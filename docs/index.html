<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>MACHINE LEARNING BASED RECONSTRUCTION STUDIES FOR DUNE NEAR
DETECTOR</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="main.tex"> 
<link rel="stylesheet" type="text/css" href="main.css"> 
</head><body 
><div class="maketitle">
                                                                                         
                                                                                         
                                                                                         
                                                                                         

<h2 class="titleHead">MACHINE LEARNING BASED RECONSTRUCTION STUDIES FOR DUNE NEAR
DETECTOR</h2>
<div class="author" ></div><br />
<div class="date" ></div>
      </div>
<!--l. 219--><p class="indent" >      &#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />
<div class="center" 
>
<!--l. 220--><p class="noindent" >
<!--l. 221--><p class="noindent" >by</div>
<div class="center" 
>
<!--l. 224--><p class="noindent" >
<!--l. 225--><p class="noindent" >Orgho Neogi</div>
<!--l. 227--><p class="noindent" >&#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />&#x00A0;<br 
class="newline" />
<div class="center" 
>
<!--l. 228--><p class="noindent" >
<!--l. 229--><p class="noindent" >A thesis submitted in partial fulfillment<br />
of the requirements for the Doctor of Philosophy<br />
degree in Physics &amp; Astronomy&#x00A0;in the<br />
Graduate College of<br />
The University of Iowa</div>
<div class="center" 
>
<!--l. 236--><p class="noindent" >
                                                                                         
                                                                                         
<!--l. 237--><p class="noindent" >May&#x00A0;2024</div>
<div class="center" 
>
<!--l. 240--><p class="noindent" >
<!--l. 241--><p class="noindent" >Thesis Committee: Name of Thesis Supervisor, Jane Nachtman</div>
<div class="center" 
>
<!--l. 243--><p class="noindent" >
<!--l. 244--><p class="noindent" >Yaser Onel</div>
<div class="center" 
>
<!--l. 246--><p class="noindent" >
<!--l. 247--><p class="noindent" >Milind Diwan</div>
<div class="center" 
>
<!--l. 249--><p class="noindent" >
<!--l. 250--><p class="noindent" >Mary Hall Reno</div>
                                                                                         
                                                                                         
<blockquote class="quote">
<!--l. 4--><p class="noindent" >I have yet to see any problem, however complicated, which, when looked at in the right way did
not become still more complicated.
<!--l. 7--><p class="noindent" >Poul Anderson<br />
</blockquote>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<div class="center" 
>
<!--l. 2--><p class="noindent" >
<!--l. 3--><p class="noindent" >ABSTRACT </div>
<!--l. 7--><p class="indent" >      Prior to your first thesis deposit, replace this text with the text of your scientific/ scholarly
abstract. The text of this abstract should be double spaced and each new paragraph should be
indented.
<div class="center" 
>
<!--l. 11--><p class="noindent" >
<!--l. 12--><p class="noindent" ><span 
class="ptmb7t-x-x-120">This abstract is required for everyone except DMA and MFA students.</span></div>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<div class="center" 
>
<!--l. 2--><p class="noindent" >
<!--l. 3--><p class="noindent" >PUBLIC ABSTRACT </div>
<!--l. 7--><p class="indent" >      Prior to your thesis deposit, replace this text with the text of your public abstract. The text of this
abstract should be double spaced and each new paragraph should be indented.
<!--l. 9--><p class="indent" >      <span 
class="ptmb7t-x-x-120">This abstract is required for all thesis/dissertations. </span>This abstract may be up to 250 words and
should be written for a non-academic lay audience. In writing your public abstract, avoid jargon and
technical language as much as possible.
<!--l. 11--><p class="indent" >      The ability to communicate research simply and clearly is an important skill. The public abstract
helps convey ideas beyond one&#8217;s immediate academic circle, facilitating communication with colleagues
who do different kinds of work and possess different dimensions of training.
<!--l. 13--><p class="indent" >      Think of your public abstract as your &#8220;elevator pitch&#8221; or what you might tell someone who asks,
&#8220;What is your thesis about?&#8221; You may only have a few minutes to explain it to them while keeping their
attention and using terminology you are sure they will understand without further lengthy
explanation.
<!--l. 15--><p class="indent" >      Another way to think of your public abstract is like the description you would read on the inside of
a book cover.
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
      <h3 class="likesectionHead"><a 
 id="x1-1000"></a>table of contents</h3>
      <div class="tableofcontents">
      &#x00A0;<span class="sectionToc" ><a 
href="#Q1-1-3">List of Tables</a></span>
<br />      &#x00A0;<span class="sectionToc" ><a 
href="#Q1-1-5">List of Figures</a></span>
<br />      &#x00A0;<span class="sectionToc" >1 <a 
href="#x1-40001" id="QQ2-1-6">Introduction</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.1 <a 
href="#x1-50001.1" id="QQ2-1-7">The Standard Model</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.2 <a 
href="#x1-60001.2" id="QQ2-1-8">The Electron</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.3 <a 
href="#x1-70001.3" id="QQ2-1-9">Dalton&#8217;s Atomic Theory</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.4 <a 
href="#x1-80001.4" id="QQ2-1-10">The Plum Pudding Model</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.5 <a 
href="#x1-90001.5" id="QQ2-1-12">Gold Foil Experiments</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.6 <a 
href="#x1-100001.6" id="QQ2-1-14">Rutherford&#8217;s Model</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.7 <a 
href="#x1-110001.7" id="QQ2-1-16">Bohr&#8217;s Model</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.8 <a 
href="#x1-120001.8" id="QQ2-1-18">The Photon</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.9 <a 
href="#x1-130001.9" id="QQ2-1-20">Duality of Matter</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.10 <a 
href="#x1-140001.10" id="QQ2-1-21">Electron Cloud Model</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.11 <a 
href="#x1-150001.11" id="QQ2-1-23">Protons and Neutrons</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.12 <a 
href="#x1-160001.12" id="QQ2-1-24">Quarks</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.13 <a 
href="#x1-170001.13" id="QQ2-1-27">The Strong Force</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >1.14 <a 
href="#x1-180001.14" id="QQ2-1-28">Electroweak Interactions</a></span>
<br />      &#x00A0;<span class="sectionToc" >2 <a 
href="#x1-190002" id="QQ2-1-29">Neutrino Detection</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >2.1 <a 
href="#x1-200002.1" id="QQ2-1-30">Detector Types</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >2.2 <a 
href="#x1-210002.2" id="QQ2-1-31">DUNE</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >2.3 <a 
href="#x1-220002.3" id="QQ2-1-32">NOVA</a></span>
<br />      &#x00A0;<span class="sectionToc" >3 <a 
href="#x1-230003" id="QQ2-1-33">Machine Learning</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >3.1 <a 
href="#x1-240003.1" id="QQ2-1-36">Perceptron Neuron</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >3.2 <a 
href="#x1-250003.2" id="QQ2-1-39">Sigmoid Neuron</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >3.3 <a 
href="#x1-260003.3" id="QQ2-1-41">Activation Functions</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >3.4 <a 
href="#x1-270003.4" id="QQ2-1-42">Neural Network</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >3.5 <a 
href="#x1-280003.5" id="QQ2-1-44">Gradient Descent</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >3.6 <a 
href="#x1-290003.6" id="QQ2-1-45">Convolutional Neural Network</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >3.7 <a 
href="#x1-300003.7" id="QQ2-1-46">Graph Neural Network</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >3.8 <a 
href="#x1-310003.8" id="QQ2-1-47">Model Development</a></span>
<br />      &#x00A0;&#x00A0;<span class="subsectionToc" >3.9 <a 
href="#x1-320003.9" id="QQ2-1-49">Model Optimization</a></span>
<br />      &#x00A0;<span class="sectionToc" ><a 
href="#Q1-1-51">References</a></span>
      </div>
                                                                                         
                                                                                         
      <h3 class="likesectionHead"><a 
 id="x1-2000"></a>List of Tables</h3>
<a 
 id="Q1-1-3"></a>
      <div class="tableofcontents"><span class="lotToc" >1&#x00A0;<a 
href="#x1-16002r1">Quark Flavors and Their Approximate Masses</a></span><br />
      </div>
                                                                                         
                                                                                         
      <h3 class="likesectionHead"><a 
 id="x1-3000"></a>List of Figures</h3>
<a 
 id="Q1-1-5"></a>
      <div class="tableofcontents"><span class="lofToc" >1&#x00A0;<a 
href="#x1-8003r1">Cartoon  of  plum  pudding  model</a></span><br /><span class="lofToc" >2&#x00A0;<a 
href="#x1-9001r2">Cartoon  of  Gold  foil
experiment</a></span><br /><span class="lofToc" >3&#x00A0;<a 
href="#x1-10001r3">Rutherford&#8217;s atomic model</a></span><br /><span class="lofToc" >4&#x00A0;<a 
href="#x1-11001r4">Bohr&#8217;s model of the hydrogen
atom</a></span><br /><span class="lofToc" >5&#x00A0;<a 
href="#x1-12001r5">Double Slit Experiment</a></span><br /><span class="lofToc" >6&#x00A0;<a 
href="#x1-14003r6">Atomic orbitals of the electron in
a hydrogen atom</a></span><br /><span class="lofToc" >7&#x00A0;<a 
href="#x1-16001r7">Quarks inside a proton. Labelled u for up and d
for down</a></span><br /><span class="lofToc" >8&#x00A0;<a 
href="#x1-23001r8">Example of a basic decision tree</a></span><br /><span class="lofToc" >9&#x00A0;<a 
href="#x1-23002r9">Example of a basic
Neural Net</a></span><br /><span class="lofToc" >10&#x00A0;<a 
href="#x1-24003r10">Perceptron Neuron</a></span><br /><span class="lofToc" >11&#x00A0;<a 
href="#x1-24005r11">Perceptron network</a></span><br /><span class="lofToc" >12&#x00A0;<a 
href="#x1-25004r12">Sigmoid
Function</a></span><br /><span class="lofToc" >13&#x00A0;<a 
href="#x1-27001r13">Parts of a Neural Net</a></span><br /><span class="lofToc" >14&#x00A0;<a 
href="#x1-31001r14">Model development</a></span><br />
      </div>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
      <h3 class="sectionHead"><span class="titlemark">1    </span> <a 
 id="x1-40001"></a>Introduction</h3>
<!--l. 3--><p class="noindent" >I have yet to see any problem, however complicated, which, when looked at in the right way did not
become still more complicated.
                                                                                         <div class="flushright" 
>
<!--l. 5--><p class="noindent" >
&#8212; Poul Anderson</div>
<!--l. 7--><p class="indent" >      People working in the field of high energy physics have a tendency to concern themselves with
attempting to solve problems that are incredibly complicated. So, perhaps, there is a touch
of irony that the problem that they are trying to solve is not only incredibly fundamental,
but also very simple to state. The question can be boiled down to &#8211; what is the stuff in our
universe made of? What immediately follows from this fundamental inquiry is how is matter
made up of these things ; or to put it another way, how do the fundamental building blocks
interact.
<!--l. 12--><p class="indent" >      In some sense particle physics tries to distill matter and the interactions therein down to the
smallest possible level to which it can be broken down. Turns out that breaking these concepts down to
this elementary level of specificity is an incredibly complicated process of which we have merely begun to
scratch the surface. As such,this paper focuses on a tiny fraction of these fundamental building blocks &#8211;
the elusive neutrino with the hope of just perhaps being able to untangle some of the myriad of secrets that
it harbours.
<!--l. 1--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">1.1    </span> <a 
 id="x1-50001.1"></a>The Standard Model</h4>
                                                                                         
                                                                                         
<!--l. 3--><p class="noindent" >Before the protagonist <span class="footnote-mark"><a 
href="main2.html#fn1x0"><sup class="textsuperscript">1</sup></a></span><a 
 id="x1-5001f1"></a> 
of our story - the neutrino - can be formally introduced, the stage has to be set. A good candidate to set the
stage would be the standard model which describesthree of the four known fundamental forces,
electromagnetic, weak and strong interactions (it struggles to deal with gravity) and classifying all known
elementary particles. Just like any foundational theory that undergirds a subfield of a subject, the standard
model definitely wasn&#8217;t developed in a day and as such, it may behoove us to at least go over the high
points ofits development in order to have a better understanding of the context that surrounds
neutrinos.
<!--l. 9--><p class="indent" >      One may definitely quibble about where our understanding of the fundamental particles starts from,
after all, humans have been trying to find out the nature of our universe and the things that make it up
going back as far as the 4th century BCE with Plato positing that everything is made up of 4
elements (water, wind, earth and fire)[<a 
href="#XTimaeus">1</a>] but I think it makes sense to start at the discovery
of the first of the particles that made it&#8217;s way into the pantheon of the standard model; the
electron.
      <h4 class="subsectionHead"><span class="titlemark">1.2    </span> <a 
 id="x1-60001.2"></a>The Electron</h4>
<!--l. 3--><p class="noindent" >For the longest time, humans had thought that atoms were the smallest particle that makes up
everything in the world and cannot be subdivided further[<a 
href="#XDalton">2</a>] but this idea had started to come
under scrutiny by the late 1800&#8217;s. Even then, it was thought that if anything were to make up
atoms, they would n&#8217;t be lighter than the lightest atom. However, in 1897, Thomson would
come in with evidence that there not only were particles that made up the atoms, but that
they were on the scale of 1000 times lighter than hydrogen. He decided to shoot cathode rays
at a thermal junction so he could measure the generated heat and neasured how much they
                                                                                         
                                                                                         
deflectedmagnetically. He also measured the electrical deflections by lowering the pressure in the chamber
where he was measuring the deflection. Through these experiments, discovered the electron
<span class="footnote-mark"><a 
href="main3.html#fn2x0"><sup class="textsuperscript">2</sup></a></span><a 
 id="x1-6001f2"></a> and
believed that it was a fundamental part of all atoms that was very light and held a decidedly negative
charge.[<a 
href="#XelectronDiscovery">3</a>]
      <h4 class="subsectionHead"><span class="titlemark">1.3    </span> <a 
 id="x1-70001.3"></a>Dalton&#8217;s Atomic Theory</h4>
<!--l. 3--><p class="noindent" >The discovery of something so much smaller than the lightest atom threw Dalton&#8217;s atomic theory out the
window. His theory claimed that everything in the universe was made up of atoms which would vary in
size and mass based on the element. These atoms could not be created or destroyed, but could
reaarrange themselves through chemical reactions. It could be argued that Dalton&#8217;s model was a
progenitor for the idea of conservation of mass and energy. Despite being such an important idea,
even before the discovery of electrons, the theory wasn&#8217;t fullproof; it could not account for
isotopes of the same element having different masses, but the electron blew the idea wide
apart.
<!--l. 9--><p class="indent" >      A new theory that looked at the atom not as the smallest thing that could exist but rather something
that had other things inside in some sort of structure had to be developed.
<!--l. 1--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">1.4    </span> <a 
 id="x1-80001.4"></a>The Plum Pudding Model</h4>
<!--l. 3--><p class="noindent" >There were numerous models that tried to tackle this problem and one of the first was proposed by
Thompson in 1904 as the plum pudding model. The first problem to grapple with was that electrons are
negatively charged while the atoms themselves are electrically neutral. To get around this, the plum
                                                                                         
                                                                                         
pudding model suggests that the electrons were suspended in a morass of positively charged particles
<span class="footnote-mark"><a 
href="main4.html#fn3x0"><sup class="textsuperscript">3</sup></a></span><a 
 id="x1-8001f3"></a> with
the charge between the positive and negative equalling out to 0. Thomson believed that the mass was
evenly distributed throughout the atom.
<!--l. 10--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 13--><p class="noindent" ><img 
src="figures/plumPudding.png" alt="PIC"  
width="284" height="284" > <a 
 id="x1-8003r1"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;1. </span><span  
class="content">Cartoon of plum pudding model                                                   </span></div><!--tex4ht:label?: x1-8003r1 -->
                                                                                         
                                                                                         
<!--l. 16--><p class="indent" >      </div><hr class="endfigure">
<!--l. 18--><p class="indent" >      The plum pudding model struggled to explain how these charged particles were so copacetic with
each other despite being such small physical distances apart. It was well known by then that opposite
charges attract while alike charges repel. It also failed to provide any explanation of the spectral lines
observed in hydrogen. Darker clouds were still on the horizon for Thomson&#8217;s plum pudding
model.
      <h4 class="subsectionHead"><span class="titlemark">1.5    </span> <a 
 id="x1-90001.5"></a>Gold Foil Experiments</h4>
<!--l. 3--><p class="noindent" >Between 1908 and 1913, a number of alpha (<span 
class="zptmcm7m-x-x-120">&#x03B1;</span>) particle scattering experiments were performed by Hans
Geiger and Ernest Marsden. These took the form of shooting <span 
class="zptmcm7m-x-x-120">&#x03B1; </span>particles at a incredibly thin piece of gold
foil. Based on the plum pudding model, it was expected that the <span 
class="zptmcm7m-x-x-120">&#x03B1; </span>particles would not be deflected
however this turned out not to be the case at all. To be fair, most of the <span 
class="zptmcm7m-x-x-120">&#x03B1; </span>particles did indeed go straight
through the gold foil, their trajectory not disturbed in the slightest. A smaller fraction did get deflected,
some by a small angle and others by a large one. But the astonishing part was that an even
smaller fraction, about 1 in 20000, shot right back at the direction the particle gun was shooting
from.
<!--l. 10--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 13--><p class="noindent" ><img 
src="figures/goldFoil.png" alt="PIC"  
width="284" height="284" > <a 
 id="x1-9001r2"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;2. </span><span  
class="content">Cartoon of Gold foil experiment                                                   </span></div><!--tex4ht:label?: x1-9001r2 -->
                                                                                         
                                                                                         
<!--l. 16--><p class="indent" >      </div><hr class="endfigure">
      <h4 class="subsectionHead"><span class="titlemark">1.6    </span> <a 
 id="x1-100001.6"></a>Rutherford&#8217;s Model</h4>
<!--l. 3--><p class="noindent" >So a new model was required to explain the discrepencies away; in comes Rutherford. He looked at the
gold foil experiments done before him and ran with it, expanding upon them and developing a new theory
on the substructure of the atom. He proposed in 1911 that atoms were mostly just empty spacewith a
highly concentrated segment of mass at the center of the atom &#8211; he called this central mass the neucleus of
the atom. In Rutherford&#8217;s atomic model, the electrons orbit around the positively charged
neucleus.
<!--l. 8--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 11--><p class="noindent" ><img 
src="figures/rutherford.png" alt="PIC"  
width="284" height="284" > <a 
 id="x1-10001r3"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;3. </span><span  
class="content">Rutherford&#8217;s atomic model                                                       </span></div><!--tex4ht:label?: x1-10001r3 -->
                                                                                         
                                                                                         
<!--l. 14--><p class="indent" >      </div><hr class="endfigure">
<!--l. 16--><p class="indent" >      Only, one little problem. When things move in a circular orbit, they are accelerating and when a
charged particle is moving in an orbit like that, it should be constantly radiating energy leading to it
eventually falling into the neucleus rendering this formulation of the atom unstable. It should also be
emitting a continous energy spectrum from the electrons, but hydrogen has discrete spectral
lines.
      <h4 class="subsectionHead"><span class="titlemark">1.7    </span> <a 
 id="x1-110001.7"></a>Bohr&#8217;s Model</h4>
<!--l. 3--><p class="noindent" >Bohr tried to come at this from an angle that resolved the spectral line issue with Rutherford&#8217;s model.
Bohr proposed that electrons move in fixed orbits, thus explaining the discrete lines of the hydrogen
spectra and that atoms emit light when an electron jumps from a higher energy level to a lower
one.
<!--l. 6--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 9--><p class="noindent" ><img 
src="figures/bohr.png" alt="PIC"  
width="284" height="284" > <a 
 id="x1-11001r4"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;4. </span><span  
class="content">Bohr&#8217;s model of the hydrogen atom                                                </span></div><!--tex4ht:label?: x1-11001r4 -->
                                                                                         
                                                                                         
<!--l. 12--><p class="indent" >      </div><hr class="endfigure">
<!--l. 14--><p class="indent" >      This still doesn&#8217;t explain away why the electron doesn&#8217;t collapse into the neucleus . However, it
does a very good job of modelling hydrogen and hydrogen-like atoms under most normal conditions.
The other issue with Bohr&#8217;s model is that it fails to adress De-Broglie&#8217;s Hypothesis of the
dual nature of matter.. To get there, we have to delve into the wonderful world of quantum
mechanics.
      <h4 class="subsectionHead"><span class="titlemark">1.8    </span> <a 
 id="x1-120001.8"></a>The Photon</h4>
<!--l. 3--><p class="noindent" >What led to the development of quantum mechanics was spirited debate about the true nature of light.
Newton was one of the first to throw his hat into the ring; in 1672 he decided to build upon the corpuscular
theory coined by Descartes, arguing that light was made up of discrete particles just like everything else.
Problem was, that around the same time Robert Hooke and Christian Huygens performed experiments that
led them to believe light was in fact not a stream of particles but rather a wave. This wave
view of light did a much better job of explaining how light refracted compared to Newtons
model.
<!--l. 8--><p class="indent" >      The position of people beliving that light was in fact a wave, not particles got a lot stronger in 1801
thanks to double slit experiments by Thomas Young. This was an experiment where there were two slits
cut into a screen and light was then shone through it being visible on another screen once it had made it
past the slits. If light was indeed made up of particles, the expectation was that we would see essentially 2
bright spots on the final screenthat corresponded to the two slits. Instead, what we got was an interference
pattern that iss typical of waves.
<!--l. 13--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 16--><p class="noindent" ><img 
src="figures/doubleSlit.png" alt="PIC"  
width="369" height="369" > <a 
 id="x1-12001r5"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;5. </span><span  
class="content">Double Slit Experiment                                                          </span></div><!--tex4ht:label?: x1-12001r5 -->
                                                                                         
                                                                                         
<!--l. 19--><p class="indent" >      </div><hr class="endfigure">
<!--l. 21--><p class="indent" >      At this point, the world is pretty much in the wave camp for the purposes of modelling light, but the
idea that light is made of particles was about to be revived from the dead by none other than Max Planck.
He was trying to solve the problem of black body radiation; namely, that the energy carried by
electromagnetic waves is emitted and absorbed in discrete quantities. His solution was to come up with
the idea of discrete quanta rather than a continously emmisive spectrum. He did this through the creation
of the what we call the Planck constant today (<span 
class="zptmcm7m-x-x-120">h</span>), a proportionality constant that he called the quantum of
action.
<!--l. 26--><p class="indent" >      This was fundamentally the introduction of quantum mechanics. a quite contentious idea at the
time, highlighted by the following quote from Bohr.
<!--l. 28--><p class="indent" >      quantum theory cannot possibly have understood it.
                                                                                         <div class="flushright" 
>
<!--l. 30--><p class="noindent" >
&#8212; Neils Bohr</div>
<!--l. 32--><p class="indent" >      Despite being frought in debate, the idea of quantum mechanics simply would not go away.
Einstein would go on to build on the Planck&#8217;s ideas and proposed that light was made up of discrete
packets of energy that he called photons. He developed the Planck-Einstein Relationship, connecting
energy and the frequency of light.
<!--l. 36--><p class="indent" >
                                                                                         
                                                                                         
<table 
class="align">
                                         <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">E </span><span 
class="zptmcm7t-x-x-120">= </span><span 
class="zptmcm7m-x-x-120">h&#x03BD;</span></td>                                         <td 
class="align-even"></td>                                         <td 
class="align-label"><a 
 id="x1-12002r1"></a>(1)                                         </td></tr></table>
<!--l. 40--><p class="indent" >      Where <span 
class="zptmcm7m-x-x-120">E </span>stands for energy, <span 
class="zptmcm7m-x-x-120">h </span>for thePlanck constant and <span 
class="zptmcm7m-x-x-120">&#x03BD; </span>for the frequency of the
photon.
<!--l. 44--><p class="indent" >      This equation was to explain the results that Einstein had gotten from his experiments
regarding the photoelectric effect. In 1914, Robert A. Millikan went on to confirm Einstein&#8217;s idea
by doing a highly accurate measurement of Plank&#8217;s Constant using the photoelectric effect.
Photons would go on to be included in the list of particles we deal with in the standard model
today.
      <h4 class="subsectionHead"><span class="titlemark">1.9    </span> <a 
 id="x1-130001.9"></a>Duality of Matter</h4>
<!--l. 1--><p class="noindent" >This new evidence went in the face of the wave nature of light which had been longstanding. It seemed
like there were phenomena that could be explained by thinking of light as a wave and other phenomena
that could be understood if we looked at light as a particle. In 1924, Louis de Broglie entered the fray and
decided to ask the question nobody had before.
<!--l. 5--><p class="indent" >      But why not both?
<!--l. 7--><p class="indent" >      He even went a step further and argued that the wave/particle dual nature was not just a thing for
light, but rather all matter.
<!--l. 9--><p class="indent" >      He further worked on Einstein&#8217;s equation, ending up with
<!--l. 11--><p class="indent" >
                                                                                         
                                                                                         
<table 
class="align">
                                       <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">h&#x03BD;</span><sub><span 
class="zptmcm7t-x-x-90">0</span></sub> <span 
class="zptmcm7t-x-x-120">= </span><span 
class="zptmcm7m-x-x-120">m</span><sub><span 
class="zptmcm7t-x-x-90">0</span></sub><span 
class="zptmcm7m-x-x-120">c</span><sup><span 
class="zptmcm7t-x-x-90">2</span></sup></td>                                       <td 
class="align-even"></td>                                       <td 
class="align-label"><a 
 id="x1-13001r2"></a>(2)                                       </td></tr></table>
<!--l. 15--><p class="indent" >      Where <span 
class="zptmcm7m-x-x-120">h </span>is the Planck constant, <span 
class="zptmcm7m-x-x-120">&#x03BD;</span><sub><span 
class="zptmcm7t-x-x-90">0</span></sub> is the frequency, <span 
class="zptmcm7m-x-x-120">m</span><sub><span 
class="zptmcm7t-x-x-90">0</span></sub> is the mass while <span 
class="zptmcm7m-x-x-120">c </span>is the speed of light in a
vaccum. Leading to Einstein&#8217;s famous equation
<!--l. 17--><p class="indent" >
<table 
class="align">
                                         <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">E </span><span 
class="zptmcm7t-x-x-120">= </span><span 
class="zptmcm7m-x-x-120">mc</span><sup><span 
class="zptmcm7t-x-x-90">2</span></sup></td>                                         <td 
class="align-even"></td>                                         <td 
class="align-label"><a 
 id="x1-13002r3"></a>(3)                                         </td></tr></table>
<!--l. 21--><p class="indent" >      Where <span 
class="zptmcm7m-x-x-120">E </span>is energy, <span 
class="zptmcm7m-x-x-120">m </span>is mass and <span 
class="zptmcm7m-x-x-120">c </span>is the speed of light in a vaccum.
<!--l. 23--><p class="indent" >      This work led to the De Broglie&#8217;s relationship between wavelength and momentum.
<!--l. 25--><p class="indent" >
                                                                                         
                                                                                         
<table 
class="align">
                                          <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">&#x03BB; </span><span 
class="zptmcm7t-x-x-120">=</span> <img 
src="main0x.png" alt="-h
p"  class="frac" align="middle"></td>                                          <td 
class="align-even"></td>                                          <td 
class="align-label"><a 
 id="x1-13003r4"></a>(4)                                          </td></tr></table>
<!--l. 29--><p class="indent" >      Where <span 
class="zptmcm7m-x-x-120">&#x03BB; </span>means wavelength, <span 
class="zptmcm7m-x-x-120">h </span>is the Planck constant and <span 
class="zptmcm7m-x-x-120">p </span>is momentum.
<!--l. 31--><p class="indent" >      This relationship can be thought of as a particle travelling through space as a wave packet.
This hypothesis was later confirmed through cathode ray diffraction and Davison-Germer
experiment.
<!--l. 34--><p class="indent" >      Erwin Schrödinger would go on to take the ideas developed by De Broglie and run with it. He
thought that if all matter can be thought of as a wave packet, there must be a wave equation to describe
them. Thus the Schrödinger&#8217;s equation was born.
<!--l. 38--><p class="indent" >
<table 
class="align">
                          <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">i</span><span 
class="zptmcm7m-x-x-120">&#x210F;</span><img 
src="main1x.png" alt="&#x2202;-&#x03A8;(r,t)
   &#x2202;t"  class="frac" align="middle"></td>                          <td 
class="align-even"> <span 
class="zptmcm7t-x-x-120">= </span><img 
src="main2x.png" alt="[    2           ]
 - -&#x02C9;h-&#x2207;2 + V (r,t)
   2m"  class="left" align="middle"><span 
class="zptmcm7t-x-x-120">&#x03A8;(</span><span 
class="ptmb7t-x-x-120">r</span><span 
class="zptmcm7m-x-x-120">,t</span><span 
class="zptmcm7t-x-x-120">)</span></td>                                                    <td 
class="align-label"><a 
 id="x1-13004r5"></a>(5)                          </td></tr></table>
<!--l. 42--><p class="indent" >      Where
      <ul class="itemize1">
      <li class="itemize">
                                                                                         
                                                                                         
      <!--l. 44--><p class="noindent" ><span 
class="zptmcm7t-x-x-120">&#x03A8;(</span><span 
class="ptmb7t-x-x-120">r</span><span 
class="zptmcm7m-x-x-120">,t</span><span 
class="zptmcm7t-x-x-120">) </span>stands for the wave function of the quantum system, which depends on both position
      <span 
class="ptmb7t-x-x-120">r </span>and time <span 
class="zptmcm7m-x-x-120">t</span>.
      </li>
      <li class="itemize">
      <!--l. 45--><p class="noindent" ><span 
class="zptmcm7m-x-x-120">i </span>is the imaginary unit.
      </li>
      <li class="itemize">
      <!--l. 46--><p class="noindent" ><span 
class="zptmcm7m-x-x-120">&#x210F;</span> is the reduced Planck constant.
      </li>
      <li class="itemize">
      <!--l. 47--><p class="noindent" ><img 
src="main3x.png" alt="&#x2202;&#x03A8;(r,t)
  &#x2202;t"  class="frac" align="middle"> denotes the partial derivative of the wave function with respect to time.
      </li>
      <li class="itemize">
      <!--l. 48--><p class="noindent" ><span 
class="zptmcm7y-x-x-120">&#x2207;</span><sup><span 
class="zptmcm7t-x-x-90">2</span></sup> is the Laplacian operator, representing the sum of second partial derivatives with respect
      to the spatial coordinates, indicating the kinetic energy term.
      </li>
      <li class="itemize">
      <!--l. 49--><p class="noindent" ><span 
class="zptmcm7m-x-x-120">V</span><span 
class="zptmcm7t-x-x-120">(</span><span 
class="ptmb7t-x-x-120">r</span><span 
class="zptmcm7m-x-x-120">,t</span><span 
class="zptmcm7t-x-x-120">) </span>is the potential energy of the system, which may vary with position and time.</li></ul>
<!--l. 1--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">1.10    </span> <a 
 id="x1-140001.10"></a>Electron Cloud Model</h4>
<!--l. 3--><p class="noindent" >The Schrödinger&#8217;s equation would pave the way for the electron cloud model of the atom we use today,
but there has to be a little more work to be done befpore we can get there. The next step in the
                                                                                         
                                                                                         
journey relates to Heisenberg and his famous uncertainity principle. In his model of the atom, he
never explicitly talked about the physical position or momentum of the electron; definitely
breaking with tradition. Instead, his theory focused on the observables of the electron, namely the
frequency of light emitted or absorbed. He would go on to refine his uncertainity principle to
state
<!--l. 7--><p class="indent" >      One can never know with perfect accuracy both of those two important factors which determine the
movement of one of the smallest particles&#8212;its position and its velocity (or momentum). It is
impossible to accurately determine both the position and velocity of a particle at the same
instant.
                                                                                         <div class="flushright" 
>
<!--l. 9--><p class="noindent" >
&#8212; Werner Heisenberg,</div>
<!--l. 11--><p class="indent" >      Or to present the idea in math form,
<!--l. 13--><p class="indent" >
<table 
class="align">
                                       <tr><td 
class="align-odd"><span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">x</span><span 
class="zptmcm7y-x-x-120">&#x22C5;</span><span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">p</span></td>                                       <td 
class="align-even"> <span 
class="zptmcm7y-x-x-120">&#x2265;</span><img 
src="main4x.png" alt="&#x02C9;h
--
2"  class="frac" align="middle"></td>                                                                              <td 
class="align-label"><a 
 id="x1-14001r6"></a>(6)
                                       </td></tr><tr><td 
class="align-odd"><span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">E </span><span 
class="zptmcm7y-x-x-120">&#x22C5;</span><span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">t</span></td>                                       <td 
class="align-even"> <span 
class="zptmcm7y-x-x-120">&#x2265;</span><img 
src="main5x.png" alt="&#x02C9;h-
2"  class="frac" align="middle"></td>                                                                              <td 
class="align-label"><a 
 id="x1-14002r7"></a>(7)                                       </td></tr></table>
                                                                                         
                                                                                         
<!--l. 18--><p class="indent" >      Where <span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">x </span>stands for the uncertainty in position, <span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">p </span>stands for the uncertainty in momentum, <span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">E</span>
stands for the uncertainty in energy, and <span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">t </span>stands for the uncertainty in time. <span 
class="zptmcm7m-x-x-120">&#x210F;</span> represents the reduced
Planck constant.
<!--l. 20--><p class="indent" >      Max Born took the uncertainity principle and applied it to Schrödinger&#8217;s equation leading him to
interpret <span 
class="zptmcm7t-x-x-120">&#x03A8; </span>as a probability amplitude. Under this model, one could not know the exact positions of the
electrons in an atom but rather a probability of the electron being in a specific position at a specific
time.
<!--l. 22--><p class="indent" >      This can be visualized as a cloud of points surrounding the neucleus where the density of the dots
indicates a higher probability of the electron being at a certain position.
<!--l. 24--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 27--><p class="noindent" ><img 
src="figures/electronCloud.png" alt="PIC"  
width="284" height="284" > <a 
 id="x1-14003r6"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;6. </span><span  
class="content">Atomic orbitals of the electron in a hydrogen atom                                  </span></div><!--tex4ht:label?: x1-14003r6 -->
                                                                                         
                                                                                         
<!--l. 30--><p class="indent" >      </div><hr class="endfigure">
<!--l. 32--><p class="indent" >      Based on this model, electrons are in a state of quantum superposition until a spatial measurment is
conducted. They don&#8217;t have fixed orbits, but rather orbitals corresponding to probabilities as can be seen
for the hydrogen atom in figure <a 
href="#x1-14003r6">6<!--tex4ht:ref: electronCloud --></a>. These orbitals surround a dense neucleus at the center of the
atom.
      <h4 class="subsectionHead"><span class="titlemark">1.11    </span> <a 
 id="x1-150001.11"></a>Protons and Neutrons</h4>
<!--l. 3--><p class="noindent" >We have looked a lot at the structure of the atom and what surrounds the nucleus, but what exactly does
the nucleus contain? To do that, we have to go back in time a little bit.
<!--l. 6--><p class="indent" >      In the early 20th century, it was understood that the nucleus, as proposed by Rutherford, was a
dense central core of the atom. However, this model did not fully explain the mass of the nucleus nor the
nature of its internal components. In 1917, Ernest Rutherford made a significant contribution by
identifying the proton. His experiments with alpha particles bombarding nitrogen gas led to the discovery
of a new particle. This was a positively charged particle in the center of the neucleus; What we call the
proton today.
<!--l. 12--><p class="indent" >      Despite Rutherford&#8217;s discovery of the proton, there remained a critical question: if the
nucleus contained protons, why did it not have enough charge to account for the total mass of
the atom? This discrepancy led to the hypothesis of the neutron, a neutral particle within the
nucleus.
<!--l. 14--><p class="indent" >      In 1932, James Chadwick provided the answer by discovering the neutron. His experiments
involved bombarding beryllium with alpha particles and analyzing the resulting radiation. He observed
that this radiation was not charged and had an equivalent mass to the proton, leading to the discovery of
the neutron.
<!--l. 18--><p class="indent" >      Between the proton and he neutron, the charge and mass of the neucleus could be explained.
However, was that really the end of the rabbit hole or were there smaller parts that made up protons and
neutrons?
                                                                                         
                                                                                         
<!--l. 1--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">1.12    </span> <a 
 id="x1-160001.12"></a>Quarks</h4>
<!--l. 3--><p class="noindent" >In the mid-20th century, the field of particle physics faced mounting evidence suggesting that protons and
neutrons were not elementary particles but had a more complex internal structure. Enter the quarks. The
concept of quarks was introduced by Murray Gell-Mann and George Zweig independently in 1964.
According to Gell-Mann&#8217;s model, protons and neutrons are composed of three quarks each. This
was a significant departure from the previously held notion that protons and neutrons were
indivisible.
<!--l. 9--><p class="indent" >      Gell-Mann&#8217;s model was initially motivated by the observation of patterns among the particles
known as baryons and mesons. Baryons (like protons and neutrons) were seen as composed of triplets of
quarks, while mesons were seen as quark-antiquark pairs.
<!--l. 12--><p class="indent" >      Around the same time, George Zweig proposed a similar idea independently, also introducing the
concept of quarks. Zweig&#8217;s model was termed the &#8220;Eightfold Way&#8221; and shared many similarities with
Gell-Mann&#8217;s model, though with some differences in the details.
<!--l. 15--><p class="indent" >      The hypothesis of quarks gained experimental support in the 1970s with deep inelastic
scattering experiments conducted at the Stanford Linear Accelerator Center (SLAC). These
experiments probed the internal structure of protons by bombarding them with high-energy electrons.
The results showed evidence of point-like particles within the protons, consistent with the
quark model. The observed scaling behavior of the structure functions in these experiments
provided strong evidence for the existence of quarks and their confinement within protons and
neutrons.
<!--l. 20--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 23--><p class="noindent" ><img 
src="figures/protonQuarks.png" alt="PIC"  
width="284" height="284" > <a 
 id="x1-16001r7"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;7. </span><span  
class="content">Quarks inside a proton. Labelled u for up and d for down                            </span></div><!--tex4ht:label?: x1-16001r7 -->
                                                                                         
                                                                                         
<!--l. 27--><p class="indent" >      </div><hr class="endfigure">
<!--l. 29--><p class="indent" >      Further confirmation of the quark model came from the discovery of additional types of quarks and
the development of Quantum Chromodynamics (QCD). QCD provided a comprehensive framework for
understanding how quarks are bound together.
<!--l. 32--><p class="indent" >      Today, quarks are understood to be fundamental constituents of matter, forming the building blocks
of protons, neutrons, and other hadrons (Composite subatomic particles that are made up of at least 2
quarks).
<!--l. 34--><p class="indent" >      We have so far discovered 6 flavors of quarks &#8211; up (<img 
src="main6x.png" alt="u " class="math">), down (<img 
src="main7x.png" alt="d " class="math">), charm (<img 
src="main8x.png" alt="c " class="math">), strange (<img 
src="main9x.png" alt="s " class="math">), top
(<img 
src="main10x.png" alt="t " class="math">), and bottom (<img 
src="main11x.png" alt="b " class="math">). Each flavor has different mass. These masses and their interactions with other
particles are crucial for the stability and properties of atomic nuclei.
      <div class="table">
                                                                                         
                                                                                         
<!--l. 38--><p class="indent" >      <hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<div class="tabular">
 <table id="TBL-2" class="tabular" 
 
><colgroup id="TBL-2-1g"><col 
id="TBL-2-1"><col 
id="TBL-2-2"><col 
id="TBL-2-3"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-2-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-1-1"  
class="td11">Quark Flavor</td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-1-2"  
class="td11">Approximate Mass (MeV/c<img 
src="main12x.png" alt="2  " class="math">)</td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-1-3"  
class="td11">Charge (e)</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-2-1"  
class="td11">Up (u)            </td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-2-2"  
class="td11">                  2.2 - 3.0</td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-2-3"  
class="td11">     +<img 
src="main13x.png" alt="2
3  " class="math"></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-3-1"  
class="td11">Down (d)       </td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-3-2"  
class="td11">                  4.7 - 5.0</td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-3-3"  
class="td11">     -<img 
src="main14x.png" alt="13  " class="math"></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-4-1"  
class="td11">Strange (s)     </td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-4-2"  
class="td11">                  95 - 105</td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-4-3"  
class="td11">     -<img 
src="main15x.png" alt="1
3  " class="math"></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-5-1"  
class="td11">Charm (c)      </td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-5-2"  
class="td11">               1270 - 1720</td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-5-3"  
class="td11">     +<img 
src="main16x.png" alt="2
3  " class="math"></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-6-1"  
class="td11">Bottom (b)     </td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-6-2"  
class="td11">               4180 - 4380</td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-6-3"  
class="td11">     -<img 
src="main17x.png" alt="1
3  " class="math"></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-7-1"  
class="td11">Top (t)           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-7-2"  
class="td11">           172000 - 173000</td><td  style="white-space:nowrap; text-align:right;" id="TBL-2-7-3"  
class="td11">     +<img 
src="main18x.png" alt="23  " class="math"></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-8-1"  
class="td11">           </td></tr></table>                                                                          </div>
<a 
 id="x1-16002r1"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Table&#x00A0;1.
</span><span  
class="content">Quark
Flavors
and
Their
Approximate
Masses
</span></div><!--tex4ht:label?: x1-16002r1 -->
                                                                                         
                                                                                         
      </div><hr class="endfloat" />
      </div>
<!--l. 57--><p class="indent" >      Quarks carry fractional electric charges. For instance, up quarks have a charge of <img 
src="main19x.png" alt="+ 23  " class="math"> e, while
down quarks have a charge of <img 
src="main20x.png" alt="- 13  " class="math"> e, where e is the elementary charge. This fractional charge is essential
for the charge balance in particles such as protons and neutrons.
<!--l. 61--><p class="indent" >      Quarks are never found in isolation due to a phenomenon known as confinement. They are always
confined within larger particles called hadrons.
<!--l. 64--><p class="indent" >      Quarks have a property called color charge, analogous to electric charge but related to the strong
force. There are three types of color charges: red, green, and blue. The strong interaction, which is
described by QCD, ensures that particles made of quarks are color-neutral.
<!--l. 68--><p class="indent" >      For each quark flavor, there exists a corresponding antiquark with the opposite charge. Antiquarks
can combine with quarks to form mesons, another category of hadrons.
      <h4 class="subsectionHead"><span class="titlemark">1.13    </span> <a 
 id="x1-170001.13"></a>The Strong Force</h4>
<!--l. 3--><p class="noindent" >Having gone over what quarks are, the interesting question to ponder is why do quarks stay together to
form hadrons? Fundamentally, why can they not exist by themselves in a stable configuration? The answer
to both of these questions is the strong force.
<!--l. 7--><p class="indent" >      It is a fundamental aspect of QCD, which is the theory describing the interactions of quarks and
gluons. Gluons are a massless particle that mediates the strong force and is part of the standard
model.
<!--l. 10--><p class="indent" >      The strong force is characterized by its incredibly short range but immense strength. It operates
effectively only at distances on the order of femtometers (1 fm = <img 
src="main21x.png" alt="10-15  " class="math"> meters).
<!--l. 13--><p class="indent" >      One of the key features of the strong force is quark confinement, which means that quarks are never
found in isolation. They are always bound within larger particles called hadrons. This is due to the nature
of the strong force, which becomes stronger as quarks move farther apart. The potential energy
associated with the strong force increases with distance, effectively confining quarks within
                                                                                         
                                                                                         
hadrons.
<!--l. 18--><p class="indent" >      The QCD Lagrangian, describes the strong force
<!--l. 20--><p class="indent" >
<table 
class="align">
                         <tr><td 
class="align-odd"><span 
class="zptmcm7y-x-x-120"><img 
src="zptmcm7y-c-4c.png" alt="L" class="-120x-x-4c" /></span><sub>QCD</sub></td>                         <td 
class="align-even"> <span 
class="zptmcm7t-x-x-120">= </span><span 
class="zptmcm7y-x-x-120">-</span><img 
src="main22x.png" alt="1-
4"  class="frac" align="middle"><span 
class="zptmcm7m-x-x-120">F</span><sub><span 
class="zptmcm7m-x-x-90">&#x03BC;&#x03BD;</span></sub><sup><span 
class="zptmcm7m-x-x-90">a</span></sup><span 
class="zptmcm7m-x-x-120">F</span><sup><span 
class="zptmcm7m-x-x-90">&#x03BC;&#x03BD;a</span></sup><span 
class="zptmcm7t-x-x-120">+</span><span class="bar-css"><span 
class="zptmcm7m-x-x-120">&#x03C8;</span></span><sub>
<span 
class="zptmcm7m-x-x-90">i</span></sub><span 
class="zptmcm7t-x-x-120">(</span><span 
class="zptmcm7m-x-x-120">i&#x03B3;</span><sup><span 
class="zptmcm7m-x-x-90">&#x03BC;</span></sup><span 
class="zptmcm7m-x-x-120">D</span><sub>
<span 
class="zptmcm7m-x-x-90">&#x03BC;</span></sub><span 
class="zptmcm7y-x-x-120">-</span><span 
class="zptmcm7m-x-x-120">m</span><sub><span 
class="zptmcm7m-x-x-90">i</span></sub><span 
class="zptmcm7t-x-x-120">)</span><span 
class="zptmcm7m-x-x-120">&#x03C8;</span><sub><span 
class="zptmcm7m-x-x-90">i</span></sub><span 
class="zptmcm7m-x-x-120">,</span></td>                                                  <td 
class="align-label"><a 
 id="x1-17001r8"></a>(8)                         </td></tr></table>
<!--l. 24--><p class="indent" >      where <img 
src="main23x.png" alt=" a
F&#x03BC;&#x03BD;  " class="math"> is the field strength tensor for the gluon fields, <img 
src="main24x.png" alt="&#x03C8;i  " class="math"> represents the quark fields, <img 
src="main25x.png" alt="  &#x03BC;
&#x03B3;  " class="math">
are the gamma matrices, and <img 
src="main26x.png" alt="D &#x03BC;  " class="math"> is the covariant derivative that includes the gluon interaction. The term
<img 
src="main27x.png" alt="  1  a  &#x03BC; &#x03BD;a
- 4F &#x03BC;&#x03BD;F  " class="math"> describes the dynamics of the gluon fields, and <img 
src="main28x.png" alt="     &#x03BC;
&#x03C8;&#x02C9;i(i&#x03B3; D &#x03BC; - mi)&#x03C8;i  " class="math"> describes the
interaction between quarks and the gluon field.
<!--l. 27--><p class="indent" >      Another fascinating property of the strong force is asymptotic freedom, which means that quarks
interact more weakly at shorter distances. This phenomenon is described by the running of the strong
coupling constant <img 
src="main29x.png" alt="&#x03B1;s  " class="math">, which decreases as quarks come closer together:
<!--l. 30--><p class="indent" >
                                                                                         
                                                                                         
<table 
class="align">
                                    <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">&#x03B1;</span><sub><span 
class="zptmcm7m-x-x-90">s</span></sub><span 
class="zptmcm7t-x-x-120">(</span><span 
class="zptmcm7m-x-x-120">Q</span><sup><span 
class="zptmcm7t-x-x-90">2</span></sup><span 
class="zptmcm7t-x-x-120">)</span></td>                                    <td 
class="align-even"> <span 
class="zptmcm7t-x-x-120">=</span> <img 
src="main30x.png" alt=" 2  2
g-(Q-)-
  4&#x03C0;"  class="frac" align="middle"><span 
class="zptmcm7m-x-x-120">,</span></td>                                                                        <td 
class="align-label"><a 
 id="x1-17002r9"></a>(9)                                    </td></tr></table>
<!--l. 34--><p class="indent" >      where <img 
src="main31x.png" alt="g(Q2)  " class="math"> is the running coupling constant that depends on the energy scale <img 
src="main32x.png" alt="Q2  " class="math">. At high
energies (short distances), <img 
src="main33x.png" alt="&#x03B1;s  " class="math"> becomes smaller, indicating weaker interactions between quarks.
Conversely, at low energies (larger distances), <img 
src="main34x.png" alt="&#x03B1;s  " class="math"> grows larger, leading to stronger interactions and quark
confinement.
<!--l. 38--><p class="indent" >      In practice, the strong force is responsible for the internal structure of hadrons. The force between
these quarks is mediated by gluons, which continuously exchange color charge and bind the quarks
together in a stable configuration. The interaction between quarks within hadrons can be described by the
potential:
<!--l. 42--><p class="indent" >
<table 
class="align">
                                      <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">V</span><span 
class="zptmcm7t-x-x-120">(</span><span 
class="zptmcm7m-x-x-120">r</span><span 
class="zptmcm7t-x-x-120">)</span></td>                                      <td 
class="align-even"> <span 
class="zptmcm7t-x-x-120">= </span><span 
class="zptmcm7y-x-x-120">-</span><img 
src="main35x.png" alt="4-
3"  class="frac" align="middle"><img 
src="main36x.png" alt="&#x03B1;s-
r"  class="frac" align="middle"><span 
class="zptmcm7m-x-x-120">,</span></td>                                                                            <td 
class="align-label"><a 
 id="x1-17003r10"></a>(10)                                      </td></tr></table>
<!--l. 46--><p class="indent" >      where <img 
src="main37x.png" alt="&#x03B1;s  " class="math"> is the strong coupling constant and <img 
src="main38x.png" alt="r " class="math"> is the distance between quarks. This potential is
known as the Cornell potential and illustrates how the force increases as quarks move further
                                                                                         
                                                                                         
apart.
<!--l. 41--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">1.14    </span> <a 
 id="x1-180001.14"></a>Electroweak Interactions</h4>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
      <h3 class="sectionHead"><span class="titlemark">2    </span> <a 
 id="x1-190002"></a>Neutrino Detection</h3>
<!--l. 3--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">2.1    </span> <a 
 id="x1-200002.1"></a>Detector Types</h4>
<!--l. 5--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">2.2    </span> <a 
 id="x1-210002.2"></a>DUNE</h4>
<!--l. 7--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">2.3    </span> <a 
 id="x1-220002.3"></a>NOVA</h4>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
      <h3 class="sectionHead"><span class="titlemark">3    </span> <a 
 id="x1-230003"></a>Machine Learning</h3>
<!--l. 3--><p class="noindent" >When looking at artificial intelligence (AI), everything falls on a spectrum from easily explainable to
being a black box when thinking about how the machine makes it&#8217;s decisions. On the easily explainable
side of things, we have things like decision trees.
<!--l. 6--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 8--><p class="noindent" ><img 
src="figures/decisionTree.png" alt="PIC"  
width="341" height="341" > <a 
 id="x1-23001r8"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;8. </span><span  
class="content">Example of a basic decision tree                                                  </span></div><!--tex4ht:label?: x1-23001r8 -->
                                                                                         
                                                                                         
<!--l. 11--><p class="indent" >      </div><hr class="endfigure">
<!--l. 13--><p class="indent" >      A decision tree is where we sort the data by asking a sequence of questions and following the
flowchart down to where it leads. By the time we are at the bottom of the tree and have classified the data
we can say exactly how the model does it&#8217;s classification. For instance if a decision tree is used for
mortgage decisions and the model says no, we can query and learn that it said no because you had too low
income or too low credit score for instance.
<!--l. 17--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 19--><p class="noindent" ><img 
src="figures/neuralNet1.png" alt="PIC"  
width="341" height="341" > <a 
 id="x1-23002r9"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;9. </span><span  
class="content">Example of a basic Neural Net                                                    </span></div><!--tex4ht:label?: x1-23002r9 -->
                                                                                         
                                                                                         
<!--l. 22--><p class="indent" >      </div><hr class="endfigure">
<!--l. 24--><p class="indent" >      By contrast, a machine learning model like a neural net is almost a black box with regards to how
the decisions are made. We can query the model and ask it what it made its decisions based on, however,
the features it picks out often isn&#8217;t decipherable to humans in any way. As in the previous example, if the
answer to a mortgage is no, we have no real idea why the model made that decision. That
being said, neural networks are often able to come up with better outcomes for classification
that simple models like decision trees are. In the mortgage example, even if the neural net
can&#8217;t tell us how it comes to the conclusion of approving a loan, it is still more likely to be
able to better tell who will be a good credit risk compared to the decision tree. That&#8217;s often
the trade off that we make when deciding on a more opaque model. That&#8217;s why even though
they are opaque in how they come up with their answers we still rely on them so heavily.
Because we can empirically test through monte-carlo studies how well they perform both in term
of efficiency as well as how often these models misidentify the data that we are throwing at
it.
<!--l. 33--><p class="indent" >      While a neural network is opaque about how the decisions are made, the model itself doesn&#8217;t have
to be a black box for us. We can take a peek under the hood and see how these models work. To do so, we
start up from the basic models like a perceptron and work our way to a graph neural network, finally
connecting it to how neutrino reconstruction works.
      <h4 class="subsectionHead"><span class="titlemark">3.1    </span> <a 
 id="x1-240003.1"></a>Perceptron Neuron</h4>
<!--l. 3--><p class="noindent" >A lot of things that seem incredibly easy to humans &#8211; such as recognizing the difference between say a cat
and a dog &#8211; are very difficult for computers to do. What makes it difficult to make that sort of
classification is that it is hard for humans to define concrete rules about what makes the picture of a
cat different than the picture of a dog. Neural nets approach this in a completely different
fashion.
<!--l. 7--><p class="indent" >      Instead of trying to define rules about the features that differentiate the
                                                                                         
                                                                                         
picture of a dog vs a cat, we instead classify a whole bunch of pictures by hand.
<span class="footnote-mark"><a 
href="main5.html#fn4x0"><sup class="textsuperscript">4</sup></a></span><a 
 id="x1-24001f4"></a> Then
throw those pictures at the algorithm with the correct answers and over time the computer learns to tell the
difference between that of a dog and a cat. We call an algorithm like this that separates things into two
piles a binary classifier. There are many different kinds of binary classifiers with a whole host
of advantages and disadvantages but we will start with one that is simple to understand; the
perceptron.
<!--l. 14--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 16--><p class="noindent" ><img 
src="figures/perceptron1.png" alt="PIC"  
width="341" height="341" > <a 
 id="x1-24003r10"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;10. </span><span  
class="content">Perceptron Neuron                                                              </span></div><!--tex4ht:label?: x1-24003r10 -->
                                                                                         
                                                                                         
<!--l. 19--><p class="indent" >      </div><hr class="endfigure">
<!--l. 21--><p class="indent" >      A perceptron takes a number of inputs that are binary in nature and produce a single binary output
ie.is this a dog? The figure <a 
href="#x1-24003r10">10<!--tex4ht:ref: perceptron1 --></a> has 3 inputs (<span 
class="zptmcm7m-x-x-120">x</span><sub><span 
class="zptmcm7t-x-x-90">1</span></sub>, <span 
class="zptmcm7m-x-x-120">x</span><sub><span 
class="zptmcm7t-x-x-90">2</span></sub> and <span 
class="zptmcm7m-x-x-120">x</span><sub><span 
class="zptmcm7t-x-x-90">3</span></sub>) although, more or fewer inputs may be used.
Each input then is given a weight &#8211; <span 
class="zptmcm7m-x-x-120">w</span><sub><span 
class="zptmcm7t-x-x-90">1</span></sub>, <span 
class="zptmcm7m-x-x-120">w</span><sub><span 
class="zptmcm7t-x-x-90">2</span></sub> and <span 
class="zptmcm7m-x-x-120">w</span><sub><span 
class="zptmcm7t-x-x-90">3</span></sub> in this case &#8211; and the output calculated
thus.
<!--l. 24--><p class="indent" >
<table 
class="align">
                             <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">y </span><span 
class="zptmcm7t-x-x-120">= </span><img 
src="main39x.png" alt="(
|
|||| 0 if &#x2211;i wixi &#x2264; threshhold,
|{
  1 if &#x2211; w x &#x003E; threshhold,
|||       i i i
|||
("  class="left" align="middle"></td>                             <td 
class="align-even"></td>                             <td 
class="align-label"><a 
 id="x1-24004r11"></a>(11)                             </td></tr></table>
<!--l. 31--><p class="indent" >      Used in this fashion, a perceptron can only make simple choices. Raising the threshold makes
the classification tighter while lowering it loosens the classification. Because the output of
a perceptron is binary, for more subtle distinctions, we can use the output of a perceptron
to feed into the input of the next one thus creating a network that is more able to measure
subtlety.
<!--l. 35--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 37--><p class="noindent" ><img 
src="figures/network.png" alt="PIC"  
width="341" height="341" > <a 
 id="x1-24005r11"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;11. </span><span  
class="content">Perceptron network                                                             </span></div><!--tex4ht:label?: x1-24005r11 -->
                                                                                         
                                                                                         
<!--l. 40--><p class="indent" >      </div><hr class="endfigure">
<!--l. 42--><p class="indent" >      Varying the weights of the inputs in combination with the threshold for the output allows us to get
different models of classification. The neurons in the first layer are only able to make simple decisions
based on the raw input but because we use their output as the input to the second layer, the
second layer can make more abstract decisions with a degree of subtlety impossible not only
with one perceptron but also with even a single layer of perceptrons. The complexity of the
discrimination by the classifier increasing with both the number and layers of perceptrons in the
network.
<!--l. 46--><p class="indent" >      With the correct weights and threshold values, we can get any binary classifier we want using a set
of perceptrons. That, however, puts us back at our original problem of classifying whether something is a
dog; namely, if we knew what features to look for (i.e.&#x00A0;what weights and threshold to use) it
wouldn&#8217;t be hard explaining to a computer what a dog was. The true innovation comes with using
learning algorithms that don&#8217;t require input from the programmer to set these weights and
thresholds.
<!--l. 50--><p class="indent" >      If we want to use algorithms that can adjust weights and thresholds (otherwise called
biases) automatically, we need some method where a small change in the weight only causes a
small change in the output. Because perceptrons are binary, this is impossible to do with only
perceptrons.
<!--l. 53--><p class="indent" >      A small change in the weight to an input to the perceptron can flip the output entirely. While this
small change in weight can make one of the outputs of the network better, it may also affect the rest of the
network behave in unpredictable ways. Going back to the dog and cat example, while changing the
weight slightly may make it better at recognizing dogs, it may wreak havoc on how cats are
identified.
<!--l. 57--><p class="indent" >      This is where sigmoid neurons come in.
      <h4 class="subsectionHead"><span class="titlemark">3.2    </span> <a 
 id="x1-250003.2"></a>Sigmoid Neuron</h4>
                                                                                         
                                                                                         
<!--l. 3--><p class="noindent" >While perceptrons are effectively step functions, flipping from <span 
class="zptmcm7t-x-x-120">0 </span>to <span 
class="zptmcm7t-x-x-120">1</span>, sigmoids are more smoothed out.
This means that a small change in the weight can lead to a small change in output. The sigmoid function
can be written as
<!--l. 7--><p class="indent" >
<table 
class="align">
                                       <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">&#x03C3; </span><span 
class="zptmcm7t-x-x-120">=</span> <img 
src="main40x.png" alt="---1---
1+ e- z"  class="frac" align="middle"></td>                                       <td 
class="align-even"></td>                                       <td 
class="align-label"><a 
 id="x1-25001r12"></a>(12)                                       </td></tr></table>
<!--l. 11--><p class="indent" >      This means that a sigmoid neuron can be written as
<!--l. 13--><p class="indent" >
<table 
class="align">
                                      <tr><td 
class="align-odd"><img 
src="main41x.png" alt="      1
-------&#x2211;w-x--b
1 + e   i ii"  class="frac" align="middle"></td>                                      <td 
class="align-even"></td>                                      <td 
class="align-label"><a 
 id="x1-25002r13"></a>(13)                                      </td></tr></table>
                                                                                         
                                                                                         
<!--l. 17--><p class="indent" >      where the <span 
class="zptmcm7m-x-x-120">b </span>stands for the bias of every input. While this looks different than the perceptron at first
glance it is just a more smoothed out version of it. One key thing that we lose with the introduction of
sigmoids is the linearity that perceptrons afforded us. What we gain is the ability for our programs to
automatically adjust their weights and biases because a small change in weights does lead to small change
in output as shown in equation <a 
href="#x1-25003r14">14<!--tex4ht:ref: bias --></a>.
<!--l. 22--><p class="indent" >
<table 
class="align">
                                 <tr><td 
class="align-odd"><span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">y </span><span 
class="zptmcm7y-x-x-120">&#x2248;</span><span 
class="zptmcm7v-x-x-120">&#x2211;</span><sub><span 
class="zptmcm7m-x-x-90">i</span></sub><img 
src="main42x.png" alt="-&#x2202;y-
&#x2202;wi"  class="frac" align="middle"><span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">w</span><sub><span 
class="zptmcm7m-x-x-90">i</span></sub><span 
class="zptmcm7t-x-x-120">+</span><img 
src="main43x.png" alt="&#x2202;y-
&#x2202;b"  class="frac" align="middle"><span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">b</span></td>                                 <td 
class="align-even"></td>                                 <td 
class="align-label"><a 
 id="x1-25003r14"></a>(14)                                 </td></tr></table>
<!--l. 26--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 28--><p class="noindent" ><img 
src="figures/sigmoid.png" alt="PIC"  
width="341" height="341" > <a 
 id="x1-25004r12"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;12. </span><span  
class="content">Sigmoid Function                                                              </span></div><!--tex4ht:label?: x1-25004r12 -->
                                                                                         
                                                                                         
<!--l. 31--><p class="indent" >      </div><hr class="endfigure">
<!--l. 33--><p class="indent" >      More than the exact formula of the sigmoid neuron what matters is the shape. As a result, other
neurons can be used in it&#8217;s stead which retain the property of having a small change in weight lead to a
small change in output. Some of the more popular of these functions (called activation functions) are
RELU and softmax. Each have their own advantages and disadvantages and may even be mixed in the
same neural network
      <h4 class="subsectionHead"><span class="titlemark">3.3    </span> <a 
 id="x1-260003.3"></a>Activation Functions</h4>
<!--l. 1--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">3.4    </span> <a 
 id="x1-270003.4"></a>Neural Network</h4>
<!--l. 3--><p class="noindent" >A number of these sigmoid neurons (or neurons with other activation functions) can be strung together to
make a neural network. Each neural network has 3 main parts.
<!--l. 6--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 8--><p class="noindent" ><img 
src="figures/neuralNet1.png" alt="PIC"  
width="341" height="341" > <a 
 id="x1-27001r13"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;13. </span><span  
class="content">Parts of a Neural Net                                                            </span></div><!--tex4ht:label?: x1-27001r13 -->
                                                                                         
                                                                                         
<!--l. 11--><p class="indent" >      </div><hr class="endfigure">
<!--l. 13--><p class="indent" >      First, we have an input layer. This is all the inputs that go into a neural network and is
usually represented as a vector. Each input adds one to the dimension of the input vector. Even
something like a 2d picture can have its rows stitched together to make one long vector of
inputs.
<!--l. 18--><p class="indent" >      The middle bits are called the hidden layer, not for any profound reason, but just to distinguish
them from the input and output layers. You can have as many hidden middle layers as you want in the
network. The trade off is usually one of efficiency and accuracy. The more hidden layers you have, the
more accurate the output will bebut at the cost of requiring more time to train because there are more
weights to get right. After a point, adding more layers does not improve accuracy in meaningful way
while still taking longer to train. This makes creating a good neural net less of a hard science and more of
an art form.
<!--l. 25--><p class="indent" >      Finally, we have the output layer. This layer usually has one neuron for each thing the classifier can
bin the input into. In the dog and cat case, we would have <span 
class="zptmcm7t-x-x-120">2 </span>output neurons, one that signifies dog and the
other cat. However, the neurons won&#8217;t directly tell us whether the picture contains a dog or a cat but rather
give us two values. One of these values indicates how likely it is for this picture to contain a cat and the
other represents the likelyhood that the picture contains a dog. After that, it is still up to us to decide
on cutoff values to determine whether we will say the picture contains a cat, a dog, both or
neither.
      <h4 class="subsectionHead"><span class="titlemark">3.5    </span> <a 
 id="x1-280003.5"></a>Gradient Descent</h4>
<!--l. 3--><p class="noindent" >So far we&#8217;ve talked about the fact that weights and biases can be adjusted and that it only
works if a small change creates only a small change in output while glossing over how
exactly the computer automatically calculates these weights. Time to peel back that layer!
                                                                                         
                                                                                         
<span class="footnote-mark"><a 
href="main6.html#fn5x0"><sup class="textsuperscript">5</sup></a></span><a 
 id="x1-28001f5"></a> We
use a technique called gradient descent.
<!--l. 8--><p class="indent" >      To start off, we need a set of inputs <span 
class="zptmcm7m-x-x-120">x </span>where we already know the answers <span 
class="zptmcm7m-x-x-120">y</span>. This is called the
training dataset. Once the weights and biases are adjusted we can then use the model to query a set of
inputs that we don&#8217;t know and be reasonably certain that it won&#8217;t give us garbage outputs. To do this
adjustment, we need to define a cost function.
<!--l. 13--><p class="indent" >
<table 
class="align">
                                <tr><td 
class="align-odd"><span 
class="zptmcm7m-x-x-120">C</span><span 
class="zptmcm7t-x-x-120">(</span><span 
class="zptmcm7m-x-x-120">w,b</span><span 
class="zptmcm7t-x-x-120">) =</span> <img 
src="main44x.png" alt="1--
2n"  class="frac" align="middle"><span 
class="zptmcm7v-x-x-120">&#x2211;</span><sub><span 
class="zptmcm7m-x-x-90">x</span></sub><span 
class="zptmcm7y-x-x-120">||</span><span 
class="zptmcm7m-x-x-120">y</span><span 
class="zptmcm7t-x-x-120">(</span><span 
class="zptmcm7m-x-x-120">x</span><span 
class="zptmcm7t-x-x-120">)</span><span 
class="zptmcm7y-x-x-120">-</span><span 
class="zptmcm7m-x-x-120">a</span><span 
class="zptmcm7y-x-x-120">||</span><sup><span 
class="zptmcm7t-x-x-90">2</span></sup></td>                                <td 
class="align-even"></td>                                <td 
class="align-label"><a 
 id="x1-28003r15"></a>(15)                                </td></tr></table>
<!--l. 17--><p class="indent" >      Where <span 
class="zptmcm7m-x-x-120">n </span>is the number of training samples and <span 
class="zptmcm7m-x-x-120">a </span>is the vector of outputs from the network. We
want a set of weights that make the cost as small as possible and we can do that through a method called
gradient descent. The function described here is not the only cost function possible but is a simple one to
start with. To use gradient descent, we can do
<!--l. 22--><p class="indent" >
                                                                                         
                                                                                         
<table 
class="align">
                                       <tr><td 
class="align-odd"><span 
class="zptmcm7t-x-x-120">&#x0394;</span><span 
class="zptmcm7m-x-x-120">v </span><span 
class="zptmcm7t-x-x-120">= </span><span 
class="zptmcm7y-x-x-120">-</span><span 
class="zptmcm7m-x-x-120">&#x03B7;</span><span 
class="zptmcm7y-x-x-120">&#x2207;</span><span 
class="zptmcm7m-x-x-120">C</span></td>                                       <td 
class="align-even"></td>                                       <td 
class="align-label"><a 
 id="x1-28004r16"></a>(16)                                       </td></tr></table>
<!--l. 26--><p class="indent" >      where <span 
class="zptmcm7m-x-x-120">v </span>is the set of weights and biases and <span 
class="zptmcm7m-x-x-120">&#x03B7; </span>is the learning rate. The more aggressive we set <span 
class="zptmcm7m-x-x-120">&#x03B7;</span>
the quicker training will go, but it may end up actually increasing the cost function. So we want an <span 
class="zptmcm7m-x-x-120">&#x03B7; </span>that
is small but not too small.
      <h4 class="subsectionHead"><span class="titlemark">3.6    </span> <a 
 id="x1-290003.6"></a>Convolutional Neural Network</h4>
<!--l. 49--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">3.7    </span> <a 
 id="x1-300003.7"></a>Graph Neural Network</h4>
<!--l. 1--><p class="noindent" >
      <h4 class="subsectionHead"><span class="titlemark">3.8    </span> <a 
 id="x1-310003.8"></a>Model Development</h4>
<!--l. 3--><p class="noindent" >Developing a neural net isn&#8217;t just about figuring out the neurons for the network and adjusting the weights.
The task of making a neural net can be broken up into 3 main parts.
<!--l. 6--><p class="indent" >      <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 8--><p class="noindent" ><img 
src="figures/mlLifecycle.png" alt="PIC"  
width="341" height="341" > <a 
 id="x1-31001r14"></a>
<br />                                                                                         <div class="caption" 
><span class="id">
Figure&#x00A0;14. </span><span  
class="content">Model development                                                             </span></div><!--tex4ht:label?: x1-31001r14 -->
                                                                                         
                                                                                         
<!--l. 11--><p class="indent" >      </div><hr class="endfigure">
<!--l. 13--><p class="indent" >      The first step of any kind of model development is looking at both what kind of data is available as
well as what kind of input we might want to make on the model. The data may be scattered about in many
places and often will require processing before it can be vectorized.
<!--l. 16--><p class="indent" >      In the context of neutrino reconstruction, this may require running monte carlo simulations with
standard software e.g. (LArSoft, NDsim) and then taking the output from those simulations,
processing it into standard images that libraries like pytorch or tensorflow can take as input. It
is also important to think about standardizing the size of those images and thinking about
how to toss out the sheer amount of data that has no hits in it because neutrino events are so
sparse.
<!--l. 19--><p class="indent" >      Once that has been done, we can look at actually implementing a neural network based on that
data. This involves setting out training pipelines which will determine how the data flows, as well as
figuring out the structure of the network that will be made. Tests also have to be written for the network so
that it can be deployed robustly. Once the training with the training dataset is complete, the model has to
be validated with a validation dataset. The validation set will also be a set where the answers are
previously known so we can see how well the model performs on data that it hasn&#8217;t previously been run
on.
<!--l. 25--><p class="indent" >      Once the model has been validated, it can finally be deployed for real world data where we don&#8217;t
have the answers. This is the inference part of the model lifecycle.
      <h4 class="subsectionHead"><span class="titlemark">3.9    </span> <a 
 id="x1-320003.9"></a>Model Optimization</h4>
<!--l. 3--><p class="noindent" >There are two parts where a model can be optimized. The first is the training phase. Models can take a
long time to train even if a lot of data is available which means it is often worth it to optimize the training
phase. This sort of optimization is called hyperparameter optimization because the actual hyperparameters
(weights and biases) aren&#8217;t being tweaked but rather the parameters that guide how they are formed. It
involves manipulating the structure of the network as well as changing factors such as the learning rate.
                                                                                         
                                                                                         
The difference between a naive implementation and an optimized one may lead to a speedup of hours for
the training.
<!--l. 10--><p class="indent" >      Training isn&#8217;t however what a network is spending most of its time doing. Most of the time a
network is used to query for answers, i.e.&#x00A0;inference. Inference speedups can be done through
a number of ways such as using more specialized hardware like FPGA&#8217;s or working with
TensorRT optimization. That can bring down the time it takes to query the model for information
which can vastly affect number of events being processed in any time period thus increasing
throughput.
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
      <h3 class="likesectionHead"><a 
 id="x1-33000"></a>References</h3>
<a 
 id="Q1-1-51"></a>
<!--l. 1--><p class="noindent" >
    <div class="thebibliography">
    <p class="bibitem" ><span class="biblabel">
<a 
 id="XTimaeus"></a>[1] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Plato John&#x00A0;Warrington.  <span 
class="ptmri7t-x-x-120">Tmaeus - Plato ; edited and translated with an introduction by</span>
    <span 
class="ptmri7t-x-x-120">John Warrington</span>. Dent ; Dutton, 1965.
    </p>
    <p class="bibitem" ><span class="biblabel">
<a 
 id="XDalton"></a>[2] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Harold  Hartley.     John  dalton,  f.r.s.  (1766-1844)  and  the  atomic  theory-a  lecture  to
    commemorate  his  bicentenary.     <span 
class="ptmri7t-x-x-120">Proceedings  of  the  Royal  Society  of  London.  Series  B,</span>
    <span 
class="ptmri7t-x-x-120">Biological Sciences</span>, 168(1013):335&#8211;359, 1967.
    </p>
    <p class="bibitem" ><span class="biblabel">
<a 
 id="XelectronDiscovery"></a>[3] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>J.&#x00A0;J. Thomson. The electron. <span 
class="ptmri7t-x-x-120">The Scientific Monthly</span>, 20(2):113&#8211;115, 1925.
</p>
    </div>
       
</body></html> 

                                                                                         


